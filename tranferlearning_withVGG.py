# -*- coding: utf-8 -*-
"""tranferLearning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Sh0NUrH28Ixiik740FfMKaKDcDZJyPtu

# Get the data from kaggle

Install kaggle for collaboratory
"""

!pip install kaggle

"""Now go and download the kaggle.json file from your account at kaggle.com. 
Then upload that file to colab
"""

from google.colab import files

files.upload()

"""Make a directory and copy the file into it"""

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

"""Give the file permissions using chmod"""

! chmod 600 ~/.kaggle/kaggle.json

"""Check that kaggle was successfully installed by listing its datasets."""

! kaggle datasets list

"""Download our required dataset (fruits-360) from kaggle."""

! kaggle datasets download -d moltean/fruits

"""Make a directory where we will work."""

! mkdir MMOODDEELL

"""Unzip the downloaded dataset into this directory."""

!unzip fruits.zip -d MMOODDEELL/

"""# Make the model

Import all necessary libraries and also the VGG model.
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

from keras.layers import Input, Lambda, Dense, Flatten, Dropout
from keras.models import Model
from keras.applications.vgg16 import VGG16
from keras.applications.vgg16 import preprocess_input
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator

from sklearn.metrics import confusion_matrix, classification_report

from glob import glob

# re-size all the images to this
IMAGE_SIZE = [32, 32] # feel free to change depending on dataset

# training config:
epochs = 5
batch_size = 32

# https://www.kaggle.com/paultimothymooney/blood-cells
# train_path = '../large_files/blood_cell_images/TRAIN'
# valid_path = '../large_files/blood_cell_images/TEST'


train_path = '/content/MMOODDEELL/fruits-360/Training'
valid_path = '/content/MMOODDEELL/fruits-360/Test'

# useful for getting number of files
image_files = glob(train_path + '/*/*.jp*g')
valid_image_files = glob(valid_path + '/*/*.jp*g')

# useful for getting number of classes
folders = glob(train_path + '/*')


# add preprocessing layer to the front of VGG
vgg = VGG16(input_shape = (32,32,3), weights='imagenet', include_top=False)

print(vgg.summary())

# don't train existing weights
for layer in vgg.layers:
  layer.trainable = False

# our layers
x = Flatten()(vgg.output)
x = Dense(1300, activation='relu')(x)

prediction = Dense(len(folders), activation='softmax')(x)

# create a model object
model = Model(inputs=vgg.input, outputs=prediction)

# view the structure of the model
model.summary()

# tell the model what cost and optimization method to use
model.compile(
  loss='categorical_crossentropy',
  optimizer='rmsprop',
  metrics=['accuracy']
)


# create an instance of ImageDataGenerator
gen = ImageDataGenerator(
  rotation_range=20,
  width_shift_range=0.1,
  height_shift_range=0.1,
  shear_range=0.1,
  zoom_range=0.2,
  horizontal_flip=True,
  vertical_flip=True,
  preprocessing_function=preprocess_input
)

# get label mapping for confusion matrix plot later
test_gen = gen.flow_from_directory(valid_path, target_size=IMAGE_SIZE)
print(test_gen.class_indices)
labels = [None] * len(test_gen.class_indices)
for k, v in test_gen.class_indices.items():
  labels[v] = k


# should be a strangely colored image (due to VGG weights being BGR)
for x, y in test_gen:
  print("min:", x[0].min(), "max:", x[0].max())
  plt.title(labels[np.argmax(y[0])])
  plt.imshow(x[0])
  plt.show()
  break


# create generators
train_generator = gen.flow_from_directory(
  train_path,
  target_size=IMAGE_SIZE,
  shuffle=True,
  batch_size=batch_size,
)

valid_generator = gen.flow_from_directory(
  valid_path,
  target_size=IMAGE_SIZE,
  shuffle=True,
  batch_size=batch_size,
)

"""# Fit the model"""

r = model.fit_generator(
  train_generator,
  validation_data=valid_generator,
  epochs=epochs,
  steps_per_epoch=len(image_files) // batch_size,
  validation_steps=len(valid_image_files) // batch_size,
)

"""Define a function to make the confusion matrix"""

def get_confusion_matrix(data_path, N):
  # we need to see the data in the same order for both predictions and targets
  
  print("Generating confusion matrix", N)
  predictions = []
  targets = []

  for x, y in gen.flow_from_directory(data_path, target_size=IMAGE_SIZE, shuffle=False, batch_size=batch_size * 2):
    p = model.predict(x)
    p = np.argmax(p, axis=1)
    y = np.argmax(y, axis=1)
    predictions = np.concatenate((predictions, p))
    targets = np.concatenate((targets, y))
    if len(targets) >= N:
      break
  cm = confusion_matrix(targets, predictions)
  return predictions, targets, cm

"""Call the function and print the confusion matrix."""

predictions = []
targets = []

predictions, targets, cm = get_confusion_matrix(train_path, len(image_files))
print(cm)
valid_cm = get_confusion_matrix(valid_path, len(valid_image_files))
print(valid_cm)

"""# Plot accuracy and loss graphs."""

# plot some data

# loss
plt.plot(r.history['loss'], label='train loss')
plt.plot(r.history['val_loss'], label='val loss')
plt.legend()
plt.show()

# accuracies
plt.plot(r.history['accuracy'], label='train acc')
plt.plot(r.history['val_accuracy'], label='val acc')
plt.legend()
plt.show()

"""# Make a classification report"""

from sklearn.metrics import classification_report

"""Print the classification report (scroll to see the whole report)"""

print(classification_report(predictions, targets))

"""# We have achieved an accuracy of 92% in a classification problem  with 120 classes! This shows us the power of VGG and transfer learning.

Finally let's save the model.
"""

model.save('fruits365-92%-VGG.h5')